{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/faithrts/Science_Explainers/blob/main/analysis/analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "Il4s_vHhFaj1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "nKJMJPjMzJj6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7be6561-a7a3-41bd-a1a0-f2f0a15a19fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "### importing libraries\n",
        "\n",
        "# basic libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# to download files\n",
        "from google.colab import files\n",
        "\n",
        "import os\n",
        "import re\n",
        "import ast\n",
        "import math\n",
        "import codecs\n",
        "\n",
        "# for word2vec\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# scipy\n",
        "from scipy.stats import chi2  ## for stats\n",
        "from scipy import spatial     ## for cosine similarity\n",
        "\n",
        "# sklearn libraries\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "# NLTK\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.stem import SnowballStemmer\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing databases"
      ],
      "metadata": {
        "id": "1jFpPaq5PE03"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### cloning git repos\n",
        "\n",
        "!git clone https://github.com/faithrts/Science_Explainers\n",
        "#!git clone https://github.com/dhmit/gender_novels\n",
        "#!git clone https://github.com/faithrts/Short_Fiction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_CUSjEnPIq3",
        "outputId": "86327a06-871c-41fa-8317-f10fe6acd79e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Science_Explainers'...\n",
            "remote: Enumerating objects: 1155, done.\u001b[K\n",
            "remote: Counting objects: 100% (31/31), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 1155 (delta 13), reused 22 (delta 8), pack-reused 1124\u001b[K\n",
            "Receiving objects: 100% (1155/1155), 95.91 MiB | 4.92 MiB/s, done.\n",
            "Resolving deltas: 100% (179/179), done.\n",
            "Updating files: 100% (917/917), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### importing dataframes:\n",
        "# [explainer/fiction]_dtm_df\n",
        "# [explainer/fiction]_tfidf_df\n",
        "# [explainer/fiction]_pos_df\n",
        "\n",
        "explainer_dtm_df = pd.read_csv('Science_Explainers/analysis/explainer_dtm.csv')\n",
        "explainer_tfidf_df = pd.read_csv('Science_Explainers/analysis/explainer_tfidf.csv')\n",
        "explainer_pos_df = pd.read_csv('Science_Explainers/analysis/explainer_pos.csv')\n",
        "\n",
        "fiction_dtm_df = pd.read_csv('Science_Explainers/analysis/fiction_dtm.csv')\n",
        "fiction_tfidf_df = pd.read_csv('Science_Explainers/analysis/fiction_tfidf.csv')\n",
        "fiction_pos_df = pd.read_csv('Science_Explainers/analysis/fiction_pos.csv')"
      ],
      "metadata": {
        "id": "a98-w61QQwcd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper functions"
      ],
      "metadata": {
        "id": "mLBY_5W3mzcG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data processing"
      ],
      "metadata": {
        "id": "y8riYTJ_BY6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### makes all the column names UPPERCASE\n",
        "def col_names_to_uppercase(df):\n",
        "  new_columns = [name.upper() for name in df.columns]\n",
        "  df.columns = new_columns\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "5ST1_3i1qkF7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StemWords(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "\n",
        "  def transform(self, list_of_passages):\n",
        "    # initializes the stemmer\n",
        "    snowball_stemmer = SnowballStemmer('english')\n",
        "    new_list_of_passages = []\n",
        "\n",
        "    for passage in list_of_passages:\n",
        "      # breaks the passage up into its component words\n",
        "      words = nltk.word_tokenize(passage)\n",
        "      new_words = [snowball_stemmer.stem(word) for word in words]\n",
        "\n",
        "      new_passage = ' '.join(new_words)\n",
        "      new_list_of_passages.append(new_passage)\n",
        "\n",
        "    return new_list_of_passages"
      ],
      "metadata": {
        "id": "q5se9WBOswxB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def refine_df_columns(list_of_titles, df):\n",
        "\n",
        "  # the new df with only the columns to keep\n",
        "  df_copy = df[list_of_titles]\n",
        "\n",
        "  return df_copy"
      ],
      "metadata": {
        "id": "tsbz9rQLVvPy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelling"
      ],
      "metadata": {
        "id": "qtSVLIAgBsIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### custom pre-processor to eliminte numbers and instances of \"_\", \"\\\", and \"—\"\n",
        "def my_preprocessor(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub('([0-9—_\\\\\\\\])', '', text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "t8bwIqU-zcC8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_df_to_data(df):\n",
        "  return df.values.tolist()"
      ],
      "metadata": {
        "id": "q8PvsCfva8lw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_and_train_log_reg_l2(x_train, y_train, max_iterations = 5000):\n",
        "\n",
        "  # logistic regression with l2 regularization\n",
        "  model = LogisticRegression(penalty = 'l2', max_iter = max_iterations)\n",
        "\n",
        "  # fitting the model\n",
        "  model = model.fit(x_train, y_train)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "hZOkiLmCuARG"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_and_train_lda(x_train, topics = 10, max_iterations = 5000):\n",
        "\n",
        "  # logistic regression with l2 regularization\n",
        "  model = LatentDirichletAllocation(n_components = topics, random_state = 11)\n",
        "\n",
        "  # fitting the model\n",
        "  model = model.fit_transform(x_train)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "tzl4oBjCZNaD"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_predictive_model(x_test, y_test, model):\n",
        "  # predicted labels\n",
        "  y_pred = model.predict(x_test)\n",
        "\n",
        "  # gets performance in terms of precision, recall, accuracy, etc.\n",
        "  report = classification_report(y_test, y_pred, target_names = ['e', 'f'], output_dict = True)\n",
        "  accuracy = round(report.get('accuracy') * 100, 2)\n",
        "\n",
        "  comparison = y_pred == y_test\n",
        "  incorrect_indices = [index for index, value in enumerate(comparison) if value == False]\n",
        "\n",
        "  return report, incorrect_indices"
      ],
      "metadata": {
        "id": "r7G0r_tXc8xQ"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split_helper(explainer_feature_df, fiction_feature_df, ran = 11):\n",
        "\n",
        "  # adds the file identity to the end of each datapoint for later identification of miscategorized files\n",
        "  if 'FILENAME' not in explainer_feature_df.columns:\n",
        "    explainer_feature_df['FILENAME'] = explainer_dtm_df['FILENAME']\n",
        "  if 'FILENAME' not in fiction_feature_df.columns:\n",
        "    fiction_feature_df['FILENAME'] = fiction_dtm_df['FILENAME']\n",
        "\n",
        "  # converts the corpora's word counts for each document into lists of feature values\n",
        "  explainer_data = convert_df_to_data(explainer_feature_df)\n",
        "  fiction_data = convert_df_to_data(fiction_feature_df)\n",
        "\n",
        "  # combines the explainer and fiction data\n",
        "  total_data = explainer_data + fiction_data\n",
        "  # creates target labels for the data\n",
        "  total_labels = ['e'] * len(explainer_data) + ['f'] * len(fiction_data)\n",
        "\n",
        "  # splits the data into training and testing (random state to keep results consistent across re-runs)\n",
        "  x_train, x_test, y_train, y_test = train_test_split(total_data, total_labels, random_state = ran)\n",
        "\n",
        "  # retrieves the filenames for later identification (removes from data before input to model)\n",
        "  filenames_train = [datapoint.pop() for datapoint in x_train]\n",
        "  filenames_test = [datapoint.pop() for datapoint in x_test]\n",
        "\n",
        "  return x_train, x_test, y_train, y_test, filenames_train, filenames_test"
      ],
      "metadata": {
        "id": "VCuoe5GANVm3"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis"
      ],
      "metadata": {
        "id": "Q_y7JDkmBiKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### assumes the matrix starts after the 5th column\n",
        "def sort_top_words(matrix_df, normalize = True):\n",
        "\n",
        "  # sums the values, result is a Pandas series\n",
        "  sum_values = matrix_df.sum()\n",
        "\n",
        "  if normalize:\n",
        "    # divides the sums by the number of words\n",
        "    sum_values = sum_values/len(sum_values)\n",
        "\n",
        "  sorted_dict = sum_values.sort_values(ascending = False).to_dict()\n",
        "\n",
        "  return sorted_dict"
      ],
      "metadata": {
        "id": "Ty5oAXKPcIGj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function from https://github.com/dhmit/gender_novels/blob/master/gender_novels/analysis/dunning.py\n",
        "def dunn_individual_word(total_words_in_corpus_1, total_words_in_corpus_2,\n",
        "                         count_of_word_in_corpus_1,\n",
        "                         count_of_word_in_corpus_2):\n",
        "    '''\n",
        "    applies dunning log likelihood to compare individual word in two counter objects\n",
        "\n",
        "    :param word: desired word to compare\n",
        "    :param m_corpus: c.filter_by_gender('male')\n",
        "    :param f_corpus: c. filter_by_gender('female')\n",
        "    :return: log likelihoods and p value\n",
        "    >>> total_words_m_corpus = 8648489\n",
        "    >>> total_words_f_corpus = 8700765\n",
        "    >>> wordcount_female = 1000\n",
        "    >>> wordcount_male = 50\n",
        "    >>> dunn_individual_word(total_words_m_corpus,total_words_f_corpus,wordcount_male,wordcount_female)\n",
        "    -1047.8610274053995\n",
        "    '''\n",
        "    a = count_of_word_in_corpus_1\n",
        "    b = count_of_word_in_corpus_2\n",
        "    c = total_words_in_corpus_1\n",
        "    d = total_words_in_corpus_2\n",
        "\n",
        "    e1 = c * (a + b) / (c + d)\n",
        "    e2 = d * (a + b) / (c + d)\n",
        "\n",
        "    dunning_log_likelihood = 2 * (a * math.log(a / e1) + b * math.log(b / e2))\n",
        "\n",
        "    if count_of_word_in_corpus_1 * math.log(count_of_word_in_corpus_1 / e1) < 0:\n",
        "        dunning_log_likelihood = -dunning_log_likelihood\n",
        "\n",
        "    p = 1 - chi2.cdf(abs(dunning_log_likelihood),1)\n",
        "\n",
        "    return dunning_log_likelihood"
      ],
      "metadata": {
        "id": "8tn9xM0EAvGL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function from https://github.com/dhmit/gender_novels/blob/master/gender_novels/analysis/dunning.py\n",
        "def dunning_total(counter1, counter2, filename_to_pickle=None):\n",
        "    '''\n",
        "    runs dunning_individual on words shared by both counter objects\n",
        "    (-) end of spectrum is words for counter_2\n",
        "    (+) end of spectrum is words for counter_1\n",
        "    the larger the magnitude of the number, the more distinctive that word is in its\n",
        "    respective counter object\n",
        "\n",
        "    use filename_to_pickle to store the result so it only has to be calculated once and can be\n",
        "    used for multiple analyses.\n",
        "\n",
        "    >>> from collections import Counter\n",
        "    >>> female_counter = Counter({'he': 1,  'she': 10, 'and': 10})\n",
        "    >>> male_counter =   Counter({'he': 10, 'she': 1,  'and': 10})\n",
        "    >>> results = dunning_total(female_counter, male_counter)\n",
        "\n",
        "    # Results is a dict that maps from terms to results\n",
        "    # Each result dict contains the dunning score...\n",
        "    >>> results['he']['dunning']\n",
        "    -8.547243830635558\n",
        "\n",
        "    # ... counts for corpora 1 and 2 as well as total count\n",
        "    >>> results['he']['count_total'], results['he']['count_corp1'], results['he']['count_corp2']\n",
        "    (11, 1, 10)\n",
        "\n",
        "    # ... and the same for frequencies\n",
        "    >>> results['he']['freq_total'], results['he']['freq_corp1'], results['he']['freq_corp2']\n",
        "    (0.2619047619047619, 0.047619047619047616, 0.47619047619047616)\n",
        "\n",
        "    :return: dict\n",
        "\n",
        "    '''\n",
        "\n",
        "    total_words_counter1 = 0\n",
        "    total_words_counter2 = 0\n",
        "\n",
        "    #get word total in respective counters\n",
        "    for word1 in counter1:\n",
        "        total_words_counter1 += counter1[word1]\n",
        "    for word2 in  counter2:\n",
        "        total_words_counter2 += counter2[word2]\n",
        "\n",
        "    #dictionary where results will be returned\n",
        "    dunning_result = {}\n",
        "    for word in counter1:\n",
        "        counter1_wordcount = counter1[word]\n",
        "        if word in counter2:\n",
        "            counter2_wordcount = counter2[word]\n",
        "\n",
        "\n",
        "            if counter1_wordcount + counter2_wordcount < 10:\n",
        "                continue\n",
        "\n",
        "            dunning_word = dunn_individual_word( total_words_counter1,  total_words_counter2,\n",
        "                                                 counter1_wordcount,counter2_wordcount)\n",
        "\n",
        "            dunning_result[word] = {\n",
        "                'dunning': dunning_word,\n",
        "                'count_total': counter1_wordcount + counter2_wordcount,\n",
        "                'count_corp1': counter1_wordcount,\n",
        "                'count_corp2': counter2_wordcount,\n",
        "                'freq_total': (counter1_wordcount + counter2_wordcount) / (total_words_counter1 +\n",
        "                                                                           total_words_counter2),\n",
        "                'freq_corp1': counter1_wordcount / total_words_counter1,\n",
        "                'freq_corp2': counter2_wordcount / total_words_counter2\n",
        "            }\n",
        "\n",
        "    return dunning_result"
      ],
      "metadata": {
        "id": "ywZlnJ8RAsYT"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_dunning_log_likelihood_test(count_dict_1, count_dict_2):\n",
        "\n",
        "  # runs the comparison\n",
        "  dunning_comparison = dunning_total(count_dict_1, count_dict_2)\n",
        "\n",
        "  # extracting the dunning values for each word\n",
        "  dunning_values = {}\n",
        "  for term in dunning_comparison:\n",
        "    dunning_values[term] = dunning_comparison[term]['dunning']\n",
        "\n",
        "  return dunning_comparison, dunning_values"
      ],
      "metadata": {
        "id": "UGHOULPSNOSn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_top_dunning_dict(dunning_values, length = ''):\n",
        "  # the sorted keys of the dunning_values dictionary\n",
        "  sorted_keys_desc = sorted(dunning_values, key = dunning_values.get, reverse = True)\n",
        "  sorted_keys_asc = sorted(dunning_values, key = dunning_values.get, reverse = False)\n",
        "\n",
        "  top_dunning_dict_desc = {}\n",
        "  top_dunning_dict_asc = {}\n",
        "\n",
        "  # if no dictionary length specified or specified length too long, do all\n",
        "  if length == '' or length > len(sorted_keys_desc):\n",
        "    length = len(sorted_keys_desc)\n",
        "\n",
        "  for i in range(length):\n",
        "    cur_word_desc = sorted_keys_desc[i]\n",
        "    cur_word_asc = sorted_keys_asc[i]\n",
        "\n",
        "    top_dunning_dict_desc[cur_word_desc] = dunning_values[cur_word_desc]\n",
        "    top_dunning_dict_asc[cur_word_asc] = dunning_values[cur_word_asc]\n",
        "\n",
        "  return top_dunning_dict_desc, top_dunning_dict_asc"
      ],
      "metadata": {
        "id": "CX-YBmgkDLUR"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_cosine_similarity(vector_1, vector_2):\n",
        "  return 1 - spatial.distance.cosine(vector_1, vector_2)"
      ],
      "metadata": {
        "id": "i82t-kMmfO0S"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_closest_vectors(list_of_vectors):\n",
        "\n",
        "  # a list to contain each vector's similarity to every other\n",
        "  vector_sim_list = [[1]*len(list_of_vectors) for i in range(len(list_of_vectors))]\n",
        "\n",
        "  # the indices and similarity value of the most similar vectors\n",
        "  closest_vector_indices = []\n",
        "  closest_sim = float('inf')\n",
        "\n",
        "  # iterates through the vectors\n",
        "  for i in range(len(list_of_vectors)):\n",
        "    for j in range(len(list_of_vectors)):\n",
        "      if i > j:\n",
        "        continue\n",
        "\n",
        "      vector_1 = list_of_vectors[i]\n",
        "      vector_2 = list_of_vectors[j]\n",
        "\n",
        "      cos_sim = compute_cosine_similarity(vector_1, vector_2)\n",
        "\n",
        "      if cos_sim < closest_sim:\n",
        "        closest_sim = cos_sim\n",
        "        closest_vector_indices = [i, j]\n",
        "\n",
        "      vector_sim_list[i][j] = cos_sim\n",
        "      vector_sim_list[j][i] = cos_sim\n",
        "\n",
        "  return vector_sim_list, closest_vector_indices"
      ],
      "metadata": {
        "id": "Ifl8CufCfZd2"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tests"
      ],
      "metadata": {
        "id": "wqjsdlKlVcNO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vocabulary test"
      ],
      "metadata": {
        "id": "-MekxWEjm1-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### finding the top words of the two corpora based on TF-IDF, and taking the words at their intersection\n",
        "\n",
        "# getting a dictionary of the top words in each corpus\n",
        "explainer_top_words_dict = sort_top_words(explainer_dtm_df.iloc[:, 6:])\n",
        "fiction_top_words_dict = sort_top_words(fiction_dtm_df.iloc[:, 6:])\n",
        "\n",
        "# the top 1000 words from each corpus\n",
        "explainer_top_words = list(explainer_top_words_dict.keys())[:1000]\n",
        "fiction_top_words = list(fiction_top_words_dict.keys())[:1000]\n",
        "\n",
        "# TO DO: RE-SORT?\n",
        "common_words = list(set(explainer_top_words).intersection(set(fiction_top_words)))\n",
        "\n",
        "# dfs with only the common words as column titles\n",
        "explainer_common_words_df = refine_df_columns(common_words, explainer_dtm_df)\n",
        "fiction_common_words_df = refine_df_columns(common_words, fiction_dtm_df)"
      ],
      "metadata": {
        "id": "Zm-pdufzUQ_F"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### logistic regression with l2 regularization trained on word frequency\n",
        "\n",
        "# gets training data, testing data, and filenames (of each datapoint in order)\n",
        "x_train, x_test, y_train, y_test, filenames_train, filenames_test = train_test_split_helper(explainer_common_words_df, fiction_common_words_df, ran = 11)\n",
        "\n",
        "# creates a model\n",
        "model = create_and_train_log_reg_l2(x_train, y_train)\n",
        "\n",
        "# performance report\n",
        "common_words_report, common_words_incorrect_indices = test_predictive_model(x_test, y_test, model)\n",
        "accuracy = round(common_words_report.get('accuracy') * 100, 2)\n",
        "\n",
        "print('The model was ' + str(accuracy) + '% accurate at distinguishing literary fiction from science explainers')"
      ],
      "metadata": {
        "id": "gvT5YZw-sjpe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c095c66b-5a65-4304-de18-a7342af927a7"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model was 96.22% accurate at distinguishing literary fiction from science explainers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### finding miscategorized texts\n",
        "common_words_miscategorized_files = [filenames_test[i] for i in common_words_incorrect_indices]\n",
        "common_words_miscategorized_files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PLxnqyaFrul",
        "outputId": "e7e3eb73-3f31-47f1-f0cc-f646f83f6b26"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['GLOBE_AND_MAIL/ScreenTime101HowMuchScreen.txt',\n",
              " 'MASSIVE_SCI/AButterflysWingsAreThePerfect.txt',\n",
              " 'CNN/MessyEatingHabitsMightRevealElusive.txt',\n",
              " 'CBC/TheDarkSkyBluesLightPollution.txt',\n",
              " 'LIT_HUB/TheLastIsland.txt',\n",
              " 'CNN/TheMaleLonelinessEpidemicAndHow.txt',\n",
              " 'NEW_YORKER/TheSecretSource.txt',\n",
              " 'NATIONAL_OBSERVER/GiantJurassiceraInsectRediscoveredHangingOutside.txt',\n",
              " 'NATIONAL_OBSERVER/TheFinalDaysOfTheBahama.txt',\n",
              " 'MASSIVE_SCI/DarkMatterMakesUpAQuarter.txt',\n",
              " 'ELECTRIC/PoetryFlashFictionAndGraphicNarrative.txt',\n",
              " 'GRANTA/TheUnfolding.txt',\n",
              " 'NPR/TakeAPeekAtWhatNasa.txt',\n",
              " 'CBC/HowIslandStudiesResearchBecameA.txt',\n",
              " 'NATIONAL_OBSERVER/AnishinaabeArtistReinventsTheLoungeChair.txt',\n",
              " 'ATLANTIC/ForTheLichens.txt',\n",
              " 'MASSIVE_SCI/NeuronsDieWithGrace.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### finding the two closest miscategorized texts\n",
        "\n",
        "# the feature vectors of the miscategorized texts\n",
        "miscategorized_datapoints = [x_test[i] for i in common_words_incorrect_indices]\n",
        "\n",
        "# computing cosine similarity\n",
        "vector_sim_list, closest_vector_indices = find_closest_vectors(miscategorized_datapoints)\n",
        "\n",
        "common_words_closest_1 = common_words_miscategorized_files[closest_vector_indices[0]]\n",
        "common_words_closest_2 = common_words_miscategorized_files[closest_vector_indices[1]]\n",
        "\n",
        "print(f'The two closests miscategorized texts are:\\n\\t{common_words_closest_1}\\n\\t{common_words_closest_2}')"
      ],
      "metadata": {
        "id": "hPT-Wtx-iCYJ",
        "outputId": "89b23043-00e1-4a2f-dbd7-1632d70d7651",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The two closests miscategorized texts are:\n",
            "\tCNN/MessyEatingHabitsMightRevealElusive.txt\n",
            "\tMASSIVE_SCI/NeuronsDieWithGrace.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part-of-Speech (POS) test"
      ],
      "metadata": {
        "id": "wg1QjH41ViWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### finding the common POS tags and refining the dataframes\n",
        "\n",
        "# finding the POS tags that both corpora have in common (should be most)\n",
        "explainer_pos_tags = explainer_pos_df.columns[10:]\n",
        "fiction_pos_tags = fiction_pos_df.columns[10:]\n",
        "common_tags = list(set(explainer_pos_tags).intersection(set(fiction_pos_tags)))\n",
        "\n",
        "# dfs with only common words as column titles\n",
        "explainer_common_tags_df = refine_df_columns(common_tags, explainer_pos_df)\n",
        "fiction_common_tags_df = refine_df_columns(common_tags, fiction_pos_df)"
      ],
      "metadata": {
        "id": "zCFHOyx1d222"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### logistic regression with l2 regularization on tag counts\n",
        "\n",
        "# gets training data, testing data, and filenames (of each datapoint in order)\n",
        "x_train, x_test, y_train, y_test, filenames_train, filenames_test = train_test_split_helper(explainer_common_tags_df, fiction_common_tags_df, ran = 11)\n",
        "\n",
        "# creates a model\n",
        "model = create_and_train_log_reg_l2(x_train, y_train, max_iterations = 5000)\n",
        "\n",
        "# performance report\n",
        "common_tags_report, common_tags_incorrect_indices = test_predictive_model(x_test, y_test, model)\n",
        "accuracy = round(common_tags_report.get('accuracy') * 100, 2)\n",
        "\n",
        "print('The model was ' + str(accuracy) + '% accurate at distinguishing literary fiction from science explainers')"
      ],
      "metadata": {
        "id": "MOmPCTqeV7jT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "537dbeea-99a2-4fee-e32d-aed1c3aa312b"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model was 97.33% accurate at distinguishing literary fiction from science explainers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### finding miscategorized texts\n",
        "common_tags_miscategorized_files = [filenames_test[i] for i in common_tags_incorrect_indices]\n",
        "common_tags_miscategorized_files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QpgsMOwQt5e",
        "outputId": "daaf7603-d46d-4d6e-d139-ebf45e6b2674"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['GLOBE_AND_MAIL/HowAScientistGotAToronto.txt',\n",
              " 'AGNI/BerlinStory.txt',\n",
              " 'LIT_HUB/TheMarchers.txt',\n",
              " 'NPR/HowManyFriendsDoAmericansHave.txt',\n",
              " 'NATIONAL_OBSERVER/GiantJurassiceraInsectRediscoveredHangingOutside.txt',\n",
              " 'NATIONAL_GEOGRAPHIC/YourCatCanRecognizeYourVoice.txt',\n",
              " 'TIN_HOUSE/AsCloseAsWeDare.txt',\n",
              " 'NATIONAL_OBSERVER/IfYouSmellLikeAFlower.txt',\n",
              " 'CBC/HowIslandStudiesResearchBecameA.txt',\n",
              " 'NATIONAL_OBSERVER/InAFamedGameParkNear.txt',\n",
              " 'NATIONAL_OBSERVER/AnishinaabeArtistReinventsTheLoungeChair.txt',\n",
              " 'ATLANTIC/ForTheLichens.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### finding the two closest miscategorized texts\n",
        "\n",
        "# the feature vectors of the miscategorized texts\n",
        "miscategorized_datapoints = [x_test[i] for i in common_tags_incorrect_indices]\n",
        "\n",
        "# computing cosine similarity\n",
        "vector_sim_list, closest_vector_indices = find_closest_vectors(miscategorized_datapoints)\n",
        "\n",
        "common_tags_closest_1 = common_tags_miscategorized_files[closest_vector_indices[0]]\n",
        "common_tags_closest_2 = common_tags_miscategorized_files[closest_vector_indices[1]]\n",
        "\n",
        "print(f'The two closests miscategorized texts are:\\n\\t{common_tags_closest_1}\\n\\t{common_tags_closest_2}')"
      ],
      "metadata": {
        "id": "sGyoUwpQjhhD",
        "outputId": "c0827745-0ead-4663-844e-9ad9359651df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The two closests miscategorized texts are:\n",
            "\tLIT_HUB/TheMarchers.txt\n",
            "\tTIN_HOUSE/AsCloseAsWeDare.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# More tests"
      ],
      "metadata": {
        "id": "MUT6_lGkVUUp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dunning log likelihood on word counts\n",
        "\n"
      ],
      "metadata": {
        "id": "TfBYG0M0Adty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### comparing the statistical frequency of words in each corpus\n",
        "\n",
        "explainer_pure_counts_dict = sort_top_words(explainer_dtm_df.iloc[:, 6:], normalize = False)\n",
        "fiction_pure_counts_dict = sort_top_words(fiction_dtm_df.iloc[:, 6:], normalize = False)\n",
        "\n",
        "dunning_comparison_words, dunning_values_words, = run_dunning_log_likelihood_test(explainer_pure_counts_dict, fiction_pure_counts_dict)\n",
        "top_dunning_dict_words_desc, top_dunning_dict_words_asc = create_top_dunning_dict(dunning_values_words, length = 30)"
      ],
      "metadata": {
        "id": "VMQxJzGBOC6p"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Top 30 words stastistically associated with science explainers:\\n')\n",
        "top_dunning_dict_words_desc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tS-UQUFyQIJ0",
        "outputId": "f79535dd-bb69-42a3-bd81-92fd00127c2a"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 30 words stastistically associated with science explainers:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'study': 5104.343204609907,\n",
              " 'researchers': 4714.655534641639,\n",
              " 'university': 4506.952314390828,\n",
              " 'scientists': 4340.23863716685,\n",
              " 'climate': 3560.3324034697393,\n",
              " 'species': 3518.9428318879777,\n",
              " 'research': 3517.719043635208,\n",
              " 'science': 2671.5113001982268,\n",
              " 'health': 2504.5615093243623,\n",
              " 'canada': 2150.2713843493316,\n",
              " 'data': 2112.520313626611,\n",
              " 'cells': 1479.308425307749,\n",
              " 'national': 1448.183178707155,\n",
              " 'disease': 1312.2113784926116,\n",
              " 'including': 1303.176969471153,\n",
              " 'published': 1301.2496937442756,\n",
              " 'studies': 1299.1320890845639,\n",
              " 'humans': 1280.3984441644582,\n",
              " 'risk': 1269.2652873705413,\n",
              " 'human': 1223.3963828111303,\n",
              " 'industry': 1209.5360687461855,\n",
              " 'based': 1145.9677530204356,\n",
              " 'carbon': 1135.8097013755698,\n",
              " 'covid': 1129.6442305695898,\n",
              " 'change': 1126.5420864028968,\n",
              " 'animals': 1095.4982146606594,\n",
              " 'bacteria': 1079.0795576187668,\n",
              " 'team': 1019.4589134300767,\n",
              " 'brain': 1004.6561554202101,\n",
              " 'effects': 992.1736876925908}"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Top 30 words stastistically associated with short stories:\\n')\n",
        "top_dunning_dict_words_asc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "137asphLQFS2",
        "outputId": "d47520ad-0ec6-45b3-e024-86436269ccbe"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 30 words stastistically associated with short stories:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mother': -3023.28931675129,\n",
              " 'father': -2657.4010680871115,\n",
              " 'man': -2364.381056203116,\n",
              " 'didn': -2338.610516809078,\n",
              " 'eyes': -1522.0459201106764,\n",
              " 'room': -1492.0554550144768,\n",
              " 'woman': -1491.5692496877564,\n",
              " 'house': -1471.8983915010847,\n",
              " 'like': -1433.9349075468945,\n",
              " 'did': -1384.9876569887242,\n",
              " 'asked': -1381.43744392407,\n",
              " 'know': -1323.8277319116664,\n",
              " 'door': -1322.2731998061631,\n",
              " 'felt': -1300.7665203797783,\n",
              " 'knew': -1285.1860549975902,\n",
              " 'head': -1261.4412310307446,\n",
              " 'wanted': -1245.733858584267,\n",
              " 'went': -1239.6604893059957,\n",
              " 'boy': -1220.1553355084038,\n",
              " 'hand': -1217.958686327311,\n",
              " 'looked': -1181.0098110927838,\n",
              " 'tell': -1168.5345348550711,\n",
              " 'face': -1128.137764731308,\n",
              " 'got': -1113.6636462202891,\n",
              " 'said': -1037.9499078796698,\n",
              " 'night': -985.4249468693233,\n",
              " 'couldn': -985.330580615611,\n",
              " 'girl': -981.3402547096658,\n",
              " 'hands': -974.9604799873531,\n",
              " 'let': -971.7541887497721}"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### preparing to do predictive modelling again\n",
        "\n",
        "# the top 60 defining words from the respective corpora\n",
        "top_60_words = list(top_dunning_dict_words_desc.keys()) + list(top_dunning_dict_words_asc.keys())\n",
        "\n",
        "# dfs with only common words as column titles\n",
        "explainer_top_words_df = refine_df_columns(top_60_words, explainer_dtm_df)\n",
        "fiction_top_words_df = refine_df_columns(top_60_words, fiction_dtm_df)"
      ],
      "metadata": {
        "id": "FEPF_8QDRHDP"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### logistic regression with l2 regularization on top statistical words\n",
        "\n",
        "# gets training data, testing data, and filenames (of each datapoint in order)\n",
        "x_train, x_test, y_train, y_test, filenames_train, filenames_test = train_test_split_helper(explainer_top_words_df, fiction_top_words_df, ran = 55)\n",
        "\n",
        "# creates a model\n",
        "model = create_and_train_log_reg_l2(x_train, y_train)\n",
        "\n",
        "# performance report\n",
        "top_words_report, top_words_incorrect_indices = test_predictive_model(x_test, y_test, model)\n",
        "accuracy = round(top_words_report.get('accuracy') * 100, 2)\n",
        "\n",
        "print('The model was ' + str(accuracy) + '% accurate at distinguishing literary fiction from science explainers')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krCVcOG7Rqyn",
        "outputId": "ad46b6f8-a7a7-4769-899f-f816c3336a11"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model was 98.67% accurate at distinguishing literary fiction from science explainers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### finding miscategorized texts\n",
        "top_words_miscategorized_files = [filenames_test[i] for i in top_words_incorrect_indices]\n",
        "top_words_miscategorized_files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mt_jKO3SU6ZR",
        "outputId": "cbfe8eb4-f7e9-4890-a711-a9ab25f72110"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NPR/TheNewWorldsHottestPepperPepper.txt',\n",
              " 'ELECTRIC/ThisApocalypseBroughtToUsBy.txt',\n",
              " 'CBC/ANewBookLaysOutWhy.txt',\n",
              " 'PARIS_REVIEW/FromAnUnfinishedNovel.txt',\n",
              " 'NPR/2PeopleWereHurtInA.txt',\n",
              " 'TIN_HOUSE/TheMissAprilHouses.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### finding the two closest miscategorized texts\n",
        "\n",
        "# the feature vectors of the miscategorized texts\n",
        "miscategorized_datapoints = [x_test[i] for i in top_words_incorrect_indices]\n",
        "\n",
        "# computing cosine similarity\n",
        "vector_sim_list, closest_vector_indices = find_closest_vectors(miscategorized_datapoints)\n",
        "\n",
        "top_words_closest_1 = top_words_miscategorized_files[closest_vector_indices[0]]\n",
        "top_words_closest_2 = top_words_miscategorized_files[closest_vector_indices[1]]\n",
        "\n",
        "print(f'The two closests miscategorized texts are:\\n\\t{top_words_closest_1}\\n\\t{top_words_closest_2}')"
      ],
      "metadata": {
        "id": "4_oT3eq6jqj5",
        "outputId": "af791730-ab89-483b-9ded-31c96b38bc28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The two closests miscategorized texts are:\n",
            "\tCBC/ANewBookLaysOutWhy.txt\n",
            "\tNPR/2PeopleWereHurtInA.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dunning log likelihood + topic modelling"
      ],
      "metadata": {
        "id": "D5B3_owcX9AM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dunning log likelihood on verbs"
      ],
      "metadata": {
        "id": "IsZiKtR5Fi26"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dunning log likelihood on POS tags"
      ],
      "metadata": {
        "id": "Y9yXYfxHFkqa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### comparing the statistical frequency of words in each corpus\n",
        "\n",
        "explainer_pure_pos_dict = sort_top_words(explainer_pos_df.iloc[:, 9:], normalize = False)\n",
        "fiction_pure_pos_dict = sort_top_words(fiction_pos_df.iloc[:, 9:], normalize = False)\n",
        "\n",
        "dunning_comparison_pos, dunning_values_pos, = run_dunning_log_likelihood_test(explainer_pure_pos_dict, fiction_pure_pos_dict)\n",
        "top_dunning_dict_pos_desc, top_dunning_dict_pos_asc = create_top_dunning_dict(dunning_values_pos, length = 15)"
      ],
      "metadata": {
        "id": "DrIvvSifF1ZH"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### POS tags associated with science explainer corpus\n",
        "print('Top 15 POS tags stastistically associated with science explainers:\\n')\n",
        "top_dunning_dict_pos_desc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_3dgC-5MsBv",
        "outputId": "5d5e7dcb-bb1b-40a2-dbfd-f2bceca7db9a"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 15 POS tags stastistically associated with science explainers:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'NNS': 26057.40560076355,\n",
              " 'NNP': 11880.227142034673,\n",
              " 'CD': 10358.688977236981,\n",
              " 'POS': 5866.264038410277,\n",
              " 'JJ': 3695.9474049878736,\n",
              " 'VBZ': 2706.8421883201554,\n",
              " 'WDT': 2395.65120182971,\n",
              " 'JJR': 2373.730070614861,\n",
              " 'NNPS': 1938.1229419804401,\n",
              " 'IN': 1882.0549391403838,\n",
              " 'RBR': 1018.112661011126,\n",
              " 'JJS': 742.0706699665345,\n",
              " 'RBS': 689.8235226748163,\n",
              " 'VBN': 538.1044151086189,\n",
              " 'MD': 258.905485093258}"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### POS tags associated with short fiction corpus\n",
        "print('Top 15 POS tags stastistically associated with short stories:\\n')\n",
        "top_dunning_dict_pos_asc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwYbcxkMM6f7",
        "outputId": "273336a7-2683-4d14-ebc8-b213abee618c"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 15 POS tags stastistically associated with short stories:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'PRP': -58501.13846990699,\n",
              " 'VBD': -33769.209531262546,\n",
              " 'PRP$': -15658.14752117962,\n",
              " 'RP': -1875.6255851084898,\n",
              " 'RB': -1667.2321902912172,\n",
              " 'WP': -751.8584655212762,\n",
              " 'UH': -646.7086309936711,\n",
              " 'WRB': -487.07678088331113,\n",
              " 'PDT': -308.55895399069243,\n",
              " 'CC': -216.6937950232268,\n",
              " 'VB': -114.69331468380369,\n",
              " 'EX': -24.95786316926302,\n",
              " 'WP$': -6.8933092378428,\n",
              " 'VBP': -0.05825205682171486,\n",
              " 'NN': 0.49129599942045843}"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    }
  ]
}